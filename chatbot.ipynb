{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f43d0c-cac1-4893-85e1-51b99c17d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatbot with static prompt and ollama model is being used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd0297a-3e87-4510-9a2f-8be623331f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 17:16:35.970 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:37.133 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\shive\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-25 17:16:37.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.608 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.611 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.628 Session state does not function when running a script without `streamlit run`\n",
      "2025-06-25 17:16:38.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.646 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.647 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.650 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:16:38.652 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "#importing this library to use ollama models locally\n",
    "\n",
    "import streamlit as st\n",
    "#streamlit helps to quickly build and deploy the app using python language.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "st.header(\"This is a very simple chatbot using an ollama model\")\n",
    "#setting the header file\n",
    "\n",
    "model = ChatOllama(model = \"llama3.2:3b\")\n",
    "\n",
    "user_input = st.text_input(\"What is your query now\")\n",
    "#for taking input in from the user and being stored in a variable.\n",
    "\n",
    "if st.button(\"Click the submit button after giving prompt\"):\n",
    "#creating a button, as when botton is clicked the code inside the if condition is executed.\n",
    "    if user_input:\n",
    "    #it is being checking that the user has some content if yes then executed otherwise go to the else part. \n",
    "        result = model.invoke(user_input)\n",
    "        st.write(result.content)\n",
    "    else:\n",
    "        st.warning(\"Please give input first inorder to get output\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c697c58-a358-41c5-ac5c-ae9783612124",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Dynamic vs Static Prompts** are two different approaches to crafting inputs (prompts) sent to a language model (like LLMs in LangChain/Ollama). Here's a clear breakdown of both:\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Static Prompt\n",
    "\n",
    "#### ‚úÖ Definition:\n",
    "\n",
    "A **static prompt** is a fixed string. It does **not change** based on user input or any dynamic data.\n",
    "\n",
    "#### üí° Example:\n",
    "\n",
    "```python\n",
    "prompt = \"Summarize the following article in a formal tone.\"\n",
    "```\n",
    "\n",
    "#### üìå Characteristics:\n",
    "\n",
    "* Hardcoded and consistent every time.\n",
    "* Easy to implement.\n",
    "* Less flexible.\n",
    "\n",
    "#### üìç Use Case:\n",
    "\n",
    "Used when the task is fixed ‚Äî e.g., always summarizing text in the same format.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Dynamic Prompt\n",
    "\n",
    "#### ‚úÖ Definition:\n",
    "\n",
    "A **dynamic prompt** is **constructed programmatically** at runtime using variables like user input, form options, or context.\n",
    "\n",
    "#### üí° Example (LangChain PromptTemplate):\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"style\"],\n",
    "    template=\"Explain the topic of {topic} in a {style} tone.\"\n",
    ")\n",
    "\n",
    "user_input = template.invoke({\n",
    "    \"topic\": \"machine learning\",\n",
    "    \"style\": \"conversational\"\n",
    "})\n",
    "```\n",
    "\n",
    "#### üìå Characteristics:\n",
    "\n",
    "* Adaptable to different users, styles, topics.\n",
    "* Personalized and context-aware.\n",
    "* Better for building applications with user interaction.\n",
    "\n",
    "#### üìç Use Case:\n",
    "\n",
    "Chatbots, AI writing tools, summarizers, coding assistants, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Summary Table\n",
    "\n",
    "| Feature         | Static Prompt              | Dynamic Prompt                      |\n",
    "| --------------- | -------------------------- | ----------------------------------- |\n",
    "| Changeable      | ‚ùå Fixed                    | ‚úÖ Variable-based                    |\n",
    "| Flexibility     | Low                        | High                                |\n",
    "| Personalization | None                       | User/context-driven                 |\n",
    "| Ideal For       | Simple or repetitive tasks | Interactive apps, tools, assistants |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60d6ca-de75-46e7-a359-8b4f74d40c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this chatbot is made on basis of the dynamic prompt\n",
    "\n",
    "#As the user is getting limited, dynamic prompts are adaptive instructions that change based on user input, session history, or other contextual factors, while static prompts remain fixed and do not change throughout the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a1e2dd-70d8-4346-a4e5-8103e6607ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 17:45:52.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:52.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.021 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.110 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.114 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.119 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.129 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.156 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.159 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.165 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.172 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 17:45:56.175 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "st.title(\"Chat with Paper Summarizer using Ollama model\")\n",
    "\n",
    "# Initialize the model (update if needed)\n",
    "model = ChatOllama(model=\"llama3.2:3b\", temperature=1.5)\n",
    "\n",
    "# User selections form the given one\n",
    "paper = st.selectbox(\n",
    "    \"Select a paper to read:\",\n",
    "    [\"Paper 1: Understanding AI\",\n",
    "     \"Paper 2: Advances in Machine Learning\",\n",
    "     \"Paper 3: Future of Robotics\"]\n",
    ")\n",
    "\n",
    "style = st.selectbox(\"Select a response style:\", [\"Formal\", \"Informal\", \"Technical\", \"Conversational\"])\n",
    "length = st.selectbox(\"Select the length of the response:\", [\"Short\", \"Medium\", \"Long\"])\n",
    "\n",
    "# Template setup\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"paper\", \"style\", \"length\"],\n",
    "    #the prompt takes input as selected paper, style, and length.\n",
    "    template=\"Please summarize the following paper in a {style} style with a {length} response: {paper}\"\n",
    ")\n",
    "\n",
    "# Format the prompt string\n",
    "user_input = template.format(paper=paper, style=style, length=length)\n",
    "\n",
    "# Display response\n",
    "if st.button(\"Submit\"):\n",
    "    result = model.invoke(user_input)\n",
    "    st.subheader(\"Response:\")\n",
    "    st.write(result.content)\n",
    "# Display model information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c801eb3-020b-48ba-bd59-a22d4651a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatbot model that keeps history consistently and can be observed wheneber needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b15b46-2229-4aa9-8283-32f07d1b4f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 18:49:16.666 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:16.669 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.182 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.185 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.188 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.190 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.192 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.198 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.201 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.203 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.205 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.216 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.218 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 18:49:18.219 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "st.header(\"Chat with an Ollama Model, mode for fun purpose only.\")\n",
    "\n",
    "# Initialize model\n",
    "model = ChatOllama(model=\"llama3.2:3b\", temperature=1.5)\n",
    "\n",
    "# Initialize session state\n",
    "if \"chat_history\" not in st.session_state:\n",
    "#when session is not started this line is being added to history initially. \n",
    "    st.session_state.chat_history = [SystemMessage(content=\"You are a helpful assistant.\")]\n",
    "\n",
    "# User input\n",
    "user_input = st.text_input(\"You:\", key=\"user_input\")\n",
    "\n",
    "# Handle submission\n",
    "if st.button(\"Send\"):\n",
    "#a button is created as when the button is clicked code inside if is executed.\n",
    "    if user_input:\n",
    "    #checks whether the input is given from user\n",
    "        st.session_state.chat_history.append(HumanMessage(content=user_input))\n",
    "        #in history part the user_inpiut is also being added.\n",
    "        result = model.invoke(st.session_state.chat_history)\n",
    "        #resuult is being invoked on including the overall history.\n",
    "        st.session_state.chat_history.append(AIMessage(content=result.content))\n",
    "        #the reply message from the model also being added to the chat history.\n",
    "        st.write(\"Bot:\", result.content)\n",
    "        #the output from the model is being responded to the user to be displayed.\n",
    "\n",
    "# Optional: Display chat history\n",
    "with st.expander(\"Show Chat History\"):\n",
    "#This creates a collapsible panel labeled ‚ÄúShow Chat History.‚Äù Users can click to expand and review the full conversation history.\n",
    "    for msg in st.session_state.chat_history:\n",
    "    #Loops through each message (system, human, and AI) stored in chat_history\n",
    "        role = \"You\" if isinstance(msg, HumanMessage) else \"Bot\" if isinstance(msg, AIMessage) else \"System\"\n",
    "        st.markdown(f\"**{role}:** {msg.content}\")\n",
    "        #Uses markdown to bold the role and display the message content nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8822a-5531-46d9-ae14-50505153bfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
